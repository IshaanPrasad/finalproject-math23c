rm(list=ls())
set.seed(123)
#Change this to location of your data
#Can use drop down menu in R studio: file->import data set-> from stata and find stata data set
setwd("/Users/abhishekmalani/Desktop/Math 23C/Data")
if (!require(foreign)) install.packages("foreign"); library(foreign)
if (!require(haven)) install.packages("haven"); library(haven)
census <- read.csv("finalproject.csv")
head(census)
index <- which(!is.na(census$Income) & !is.na(census$CensusTract) & !is.na(census$State)
& !is.na(census$County) & !is.na(census$TotalPop) & !is.na(census$Citizen)& !is.na(census$Men)
& !is.na(census$Women) & !is.na(census$Hispanic) & !is.na(census$White) & !is.na(census$Black)
& !is.na(census$Native) & !is.na(census$Asian) & !is.na(census$Pacific) & !is.na(census$IncomeErr)
& !is.na(census$IncomePerCap) & !is.na(census$IncomePerCapErr) & !is.na(census$Poverty)
& !is.na(census$ChildPoverty) & !is.na(census$Professional) & !is.na(census$Service)
& !is.na(census$Office) & !is.na(census$Construction) & !is.na(census$Production)
& !is.na(census$Drive) & !is.na(census$Carpool) & !is.na(census$Transit) & !is.na(census$Walk)
& !is.na(census$OtherTransp) & !is.na(census$WorkAtHome) & !is.na(census$MeanCommute)
& !is.na(census$Employed) & !is.na(census$PrivateWork) & !is.na(census$PublicWork)
& !is.na(census$SelfEmployed) & !is.na(census$FamilyWork) & !is.na(census$Unemployment)               )
clean <- census[index,]
head(clean)
write.csv(clean,"clean.csv")  #look at this in Excel or as a text file
median(clean$Income)
length(clean$Income)
head(clean)
median(clean$Income)
length(clean$Income)
hist(clean$Income)
h = hist(clean$Income, probability = TRUE) # or hist(x,plot=FALSE) to avoid the plot of the histogram
h$density = h$counts/sum(h$counts)
plot(h,freq=FALSE)
#To find the best fitting normal distribution, compute the mean and variance of the data
mu <- mean(clean$Income); mu
sigma <- sd(clean$Income)     #estimates square root of the population variance
curve(dnorm(x, mu, sigma), from = 0, to = 250000, add = TRUE, col = "red")
head(clean)
income = clean$Income
hispanic = clean$Hispanic
white = clean$White
black = clean$Black
native = clean$Native
asian = clean$Asian
pacific = clean$Pacific
mostlywhite = clean[which(white>80)]
mostlywhite = clean$Income[which(white>80)]
mostlywhite = clean$Income[which(white>80)]; mostlywhite
mostlyblack = clean$Income[which(black>80)]; mostlyblack
mostlyhispanic = clean$Income[which(hispanic>80)]
mostlyasian = clean$Income[which(asian>80)]
mostlywhite = clean$Income[which(white>80)]; mostlywhite; length(mostlywhite)
mostlyblack = clean$Income[which(black>80)];  length(mostlyblack)
mostlyhispanic = clean$Income[which(hispanic>80)];  length(mostlyhispanic)
mostlyasian = clean$Income[which(asian>80)]; length(mostlyasian)
mostlynative = clean$Income[which(native>80)]; length(mostlynative)
mostlypacific = clean$Income[which(pacific>80)]; length(mostlypacific)
mostlywhite = clean$Income[which(white>75)]; mostlywhite; length(mostlywhite)
mostlyblack = clean$Income[which(black>75)];  length(mostlyblack)
mostlyhispanic = clean$Income[which(hispanic>75)];  length(mostlyhispanic)
mostlyasian = clean$Income[which(asian>75)]; length(mostlyasian)
mostlynative = clean$Income[which(native>75)]; length(mostlynative)
mostlypacific = clean$Income[which(pacific>75)]; length(mostlypacific)
head(clean)
mean(clean$Asian)
mostlyasian = clean$Income[which(asian>50)]; length(mostlyasian)
whiteincome = mean(mostlywhite)
blackincome = mean(mostlyblack)
hispanicincome = mean(mostlyhispanic)
asianincome = mean(mostlyasian)
nativeincome = mean(mostlynative)
mostlypacific = clean$Income[which(pacific>50)]; length(mostlypacific)
mostlypacific = clean$Income[which(pacific>75)]; length(mostlypacific)
pacificincome = mean(mostlypacific)
whiteincome; blackincome;hispanicincome;asianincome;nativeincome;pacificincome
plot(whiteincome; blackincome;hispanicincome;asianincome;nativeincome;pacificincome)
plot(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome)
barplot(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome)
?barplot
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome))
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"))
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"), col =c("white", "black","brown", "yellow", "red", "blue"))
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"), col =c("white", "black","brown", "yellow", "red", "tan"))
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"), col =c("white", "black","brown", "yellow", "red", "tan"),main = "Income")
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"),main = "Income")
plot(c(0,0), (1,200000))
c
plot(c(0,0), c(1,200000))
scatter.smooth(c(0,0), c(1,200000))
scatter.smooth(c(0,0), c(1,200000))
scatter.smooth(c(0,1), c(0,200000))
plot(c(0,1), c(0,200000))
hispanic = which(clean$Hispanic>75)
white = which(clean$White>75)
black = which(clean$Black>75)
native = which(clean$Native>75)
asian = which(clean$Asian>75)
pacific = which(clean$Pacific>75)
mostlywhite = clean$Income[white]; mostlywhite; length(mostlywhite)
mostlyblack = clean$Income[black];  length(mostlyblack)
mostlyhispanic = clean$Income[hispanic];  length(mostlyhispanic)
mostlyasian = clean$Income[asian]; length(mostlyasian)
mostlynative = clean$Income[native]; length(mostlynative)
mostlypacific = clean$Income[pacific]; length(mostlypacific)
whiteincome = mean(mostlywhite)
blackincome = mean(mostlyblack)
hispanicincome = mean(mostlyhispanic)
asianincome = mean(mostlyasian)
nativeincome = mean(mostlynative)
pacificincome = mean(mostlypacific)
whiteincome; blackincome;hispanicincome;asianincome;nativeincome;pacificincome
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"),main = "Income")
hispanic = which(clean$Hispanic>75);  length(mostlyhispanic)
white = which(clean$White>75); length(mostlywhite)
black = which(clean$Black>75);  length(mostlyblack)
native = which(clean$Native>75); length(mostlynative)
asian = which(clean$Asian>75); length(mostlyasian)
pacific = which(clean$Pacific>75); length(mostlypacific)
whitepoverty = mean(mostlywhite)
blackpoverty = mean(mostlyblack)
hispanicpoverty = mean(mostlyhispanic)
asianpoverty = mean(mostlyasian)
nativepoverty = mean(mostlynative)
pacificpoverty = mean(mostlypacific)
whitepoverty; blackpoverty;hispanicpoverty;asianpoverty;nativepoverty;pacificpoverty
mostlywhite = clean$Poverty[white]
mostlyblack = clean$Poverty[black]
mostlyhispanic = clean$Poverty[hispanic]
mostlyasian = clean$Poverty[asian]
mostlynative = clean$Poverty[native]
mostlypacific = clean$Poverty[pacific]
whitepoverty = mean(mostlywhite)
blackpoverty = mean(mostlyblack)
hispanicpoverty = mean(mostlyhispanic)
asianpoverty = mean(mostlyasian)
nativepoverty = mean(mostlynative)
pacificpoverty = mean(mostlypacific)
whitepoverty; blackpoverty;hispanicpoverty;asianpoverty;nativepoverty;pacificpoverty
barplot(c(whitepoverty,blackpoverty,hispanicpoverty,asianpoverty,nativepoverty,pacificpoverty), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"),main = "Income")
barplot(c(whitepoverty,blackpoverty,hispanicpoverty,asianpoverty,nativepoverty,pacificpoverty), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"),main = "Poverty")
rm(list=ls())
set.seed(123)
#Change this to location of your data
setwd("/Users/abhishekmalani/Desktop/Math 23C/finalproject-math23c")
?setwd
getwd()
setwd("/Users/abhishekmalani/Desktop/Math 23C/Data")
setwd("Users/abhishekmalani/Desktop/Math 23C/Data")
#Change this to location of your data
#Can use drop down menu in R studio: file->import data set-> from stata and find stata data set
setwd("/Users/Abhishekmalani/Desktop/Math 23C/Data")
#Change this to location of your data
setwd(/Users/abhishekmalani/Desktop/Math 23C/finalproject-math23c)
getwd()
#Change this to location of your data
#Can use drop down menu in R studio: file->import data set-> from stata and find stata data set
setwd("/Users/Massimo/Documents/Math 23c/Data")
#Change this to location of your data
#Can use drop down menu in R studio: file->import data set-> from stata and find stata data set
setwd("/Users/abishekmalani/Documents/Math 23c")
#Change this to location of your data
#Can use drop down menu in R studio: file->import data set-> from stata and find stata data set
setwd("/abishekmalani/Documents/Math 23c")
#Topic 4: Logistic regression
SOX <- read.csv("RedSox2013.csv"); head(SOX)
#Convert the WonLost column to a Bernoulli random variable
wins <- (as.numeric(SOX$WonLost=="W")); head(wins)
#Extract the runs scored column
runs <- SOX$R
plot(runs,wins)  #not a great candidate for a straight-line approximation, but let's try
b <- cov(runs,wins)/var(runs)    #easy way to get the slope
#Here is the formula for the intercept
a <- mean(wins) - b*mean(runs);a
#We can add this regression line to the plot of the data
abline(a, b, col = "red")
#Instead, we assume that p = exp(alpha x+beta)/(1 + exp(alpha x+beta))
#This function can never be less than zero nor greater than 1
#Start with minus the log of the likelihood function
MLL<- function(alpha, beta) {
-sum( log( exp(alpha+beta*runs)/(1+exp(alpha+beta*runs)) )*wins
+ log(1/(1+exp(alpha+beta*runs)))*(1-wins) )
}
#R has a function that will maximize this function of alpha and beta
#install.packages("stats4")   #needs to be run at most once
library(stats4)
results<-mle(MLL, start = list(alpha = 0, beta = 0)) #an initial guess is required
results@coef
curve( exp(results@coef[1]+results@coef[2]*x)/ (1+exp(results@coef[1]+results@coef[2]*x)),col = "blue", add=TRUE)
#The curve shows a good model for the probability of winning as a function of runs
abline(h=0.5)
abline(v=c(3,4))
index <- which(runs == 3); head(index)   #games with 3 runs
mean(wins[index])   #won 34%
index <- which(runs == 4)    #games with 4 runs
mean(wins[index])   #won 63%
index <- which(runs == 7)    #games with 7 runs
mean(wins[index])   #won 88%
index <- which(runs == 9)    #games with 9 runs
mean(wins[index])   #won 100%
if (!require(stats4)) install.packages("stats4"); library(stats4)
barplot(c(whiteincome, blackincome, hispanicincome, asianincome, nativeincome, pacificincome), names.arg = c("white", "black", "hispanic", "asian", "native", "pacific"),main = "Income")
clean = read.csv("clean.csv")
rm(list=ls())
set.seed(123)
#Change this to location of your data
#Can use drop down menu in R studio: file->import data set-> from stata and find stata data set
setwd("/Users/abhishekmalani/Desktop/Math 23C/Data")
if (!require(foreign)) install.packages("foreign"); library(foreign)
if (!require(haven)) install.packages("haven"); library(haven)
if (!require(randomForest)) install.packages("randomForest"); library(randomForest)
if (!require(rpart)) install.packages("rpart"); library(rpart)
if (!require(stats4)) install.packages("stats4"); library(stats4)
census <- read.csv("finalproject.csv")
census <- read.csv("finalproject.csv")
census <- read.csv("finalproject.csv")
rm(list=ls())
set.seed(123)
#Change this to location of your data
#Can use drop down menu in R studio: file->import data set-> from stata and find stata data set
setwd("/Users/abhishekmalani/Desktop/Math 23C/Data")
if (!require(foreign)) install.packages("foreign"); library(foreign)
if (!require(haven)) install.packages("haven"); library(haven)
if (!require(randomForest)) install.packages("randomForest"); library(randomForest)
if (!require(rpart)) install.packages("rpart"); library(rpart)
if (!require(stats4)) install.packages("stats4"); library(stats4)
census <- read.csv("finalproject.csv")
clean = read.csv("clean.csv")
length(chicago); length(orlando)
chicago = which(clean$County == "Cook" & clean$State == "Illinois")
rm(list=ls())
set.seed(123)
setwd("/Users/Massimo/Documents/Math 23C/finalproject-math23c")
clean = read.csv("clean.csv")
### Unemployment vs. Income ###
#Point 9 - a relationship that might have been statistically significant but that turns out not to be so
poverty = clean$Walk[cali]
chicago = which(clean$County == "Cook" & clean$State == "Illinois")
orlando = which(clean$County == "Orange" & clean$State == "Florida")
mean(clean$Walk[chicago]); mean(clean$Walk[orlando])
length(chicago); length(orlando)
length(chicago); length(orlando)
obs = mean(clean$Walk[orlando]) - mean(clean$Walk[chicago]); obs
#Trying to do Permutation Test here
sum(clean$State == "Massachusetts"); sum(clean$State == "Alabama")
MaSample <- sample (clean$State == "Massachusetts", size=1172, replace =F)
length(MaSample)
#Calculate the observed beer consumption difference by State
MassAvg <- sum(clean$Income*(clean$State == "Massachusetts"))/sum(clean$State == "Massachusetts"); MassAvg
AlabAvg <- sum(clean$Income*(clean$State == "Alabama"))/sum(clean$State == "Alabama");AlabAvg
observed <- MassAvg - AlabAvg; observed     #the men drank more beer
chicago = which(clean$County == "Cook" & clean$State == "Illinois")
orlando = which(clean$County == "Orange" & clean$State == "Florida")
mean(clean$Walk[chicago]); mean(clean$Walk[orlando])
obs = mean(clean$Walk[orlando]) - mean(clean$Walk[chicago]); obs
length(chicago); length(orlando)
#Now replace Orlando with a random sample of all the data
County <- sample(clean$County); head(County)   #permuted State column
sum(clean$State == "Florida" & County == "Orange")
chicago = which(clean$County == "Cook" & clean$State == "Illinois")
length(chicago); length(orlando)
sum(clean$County == "Cook")
sum(clean$County == "Cook" & clean$State == "Illinois")
sum(clean$County == "Cook" & clean$State == "Alabama")
sum(clean$County == "Cook" & clean$State == "Georgia")
sum(clean$County == "Cook" & clean$State == "Minnesota")
chicago = which(clean$County == "Cook" & clean$State == "Illinois")
orlando = which(clean$County == "Orange" & clean$State == "Florida")
mean(clean$Walk[chicago]); mean(clean$Walk[orlando])
obs = mean(clean$Walk[orlando]) - mean(clean$Walk[chicago]); obs
length(chicago); length(orlando)
sum(County == "Cook")
#Now replace Orlando with a random sample of all the data
County <- sample(clean$County & clean$State); head(County)   #permuted County column
is.chicago = clean$County == "Cook" & clean$State == "Illinois"; head(is.chicago)
clean2 = cbind(clean,is.chicago)
sum(is.chicago)
length(is.chicago)
clean2 = cbind(clean,is.chicago)
#Now replace Chicago with a random sample of all the data
permute <- sample(clean2$is.chicago); head(permute)   #permuted is.chicago column
sum(permute)
ChicagoAvg <- sum(clean$Walk*is.chicago)/sum(is.chicago); ChicagoAvg
#We can't just permute the County column, because Cook county exists in multiple states
#So we create and add a column specific to Chicago
is.chicago = as.numeric(clean$County == "Cook" & clean$State == "Illinois"); head(is.chicago)
length(is.chicago); sum(is.chicago)  #Seems right
is.orlando = as.numeric(clean$County == "Orange" & clean$State == "Florida"); head(is.orlando)
length(is.orlando); sum(is.orlando)  #Seems right
city = is.chicago + 2*is.orlando; head(city)
clean2 = cbind(clean,city)
sum(which(city == 1)); sum(which(city == 2))
sum(city == 1); sum(city == 2)
#Now replace Chicago with a random sample of all the data
permute <- sample(clean2$city); head(permute)   #permuted is.chicago column
sum(permute)
#Now replace Chicago with a random sample of all the data
permute <- sample(clean$city); head(permute)   #permuted city column
#Now replace Chicago with a random sample of all the data
permute <- sample(city); head(permute)   #permuted city column
ChicagoAvg <- sum(clean$Walk*(permute == 1))/sum(permute ==1); ChicagoAvg
OrlandoAvg <- sum(clean$Walk*(permute == 2))/sum(permute == 2); OrlandoAvg
OrlandoAvg - ChicagoAvg    #as likely to be negative or positive
#Repeat 10000 times
N <- 10000
diffs <- numeric(N)
for (i in 1:N){
permute <- sample(city); head(permute)
ChicagoAvg <- sum(clean$Walk*(permute == 1))/sum(permute == 1)
OrlandoAvg <- sum(clean$Walk*(permute == 2))/sum(permute == 2)
diffs[i] <- OrlandoAvg - ChicagoAvg
}
mean(diffs) #should be close to zero
mean(diffs)
hist(diffs, breaks = "FD")
#Now display the observed difference on the histogram
abline(v = observed, col = "red")
hist(diffs, breaks = "FD", xlim = c(-3,3))
#Now display the observed difference on the histogram
abline(v = observed, col = "red")
obs = mean(clean$Walk[orlando]) - mean(clean$Walk[chicago]); obs
hist(diffs, breaks = "FD", xlim = c(-4,2))
#Now display the observed difference on the histogram
abline(v = observed, col = "red")
#Now display the observed difference on the histogram
abline(v = obs, col = "red")
hist(diffs, breaks = "FD", xlim = c(-3,2))
hist(diffs, breaks = "FD", xlim = c(-3,3))
#Now display the observed difference on the histogram
abline(v = obs, col = "red")
#What is the probability (the P value) that a difference this large
#could have arisen with a random subset?
pvalue <- (sum(diffs >= obs)+1)/(N+1); pvalue
orlando = which(clean$County == "Los Angeles" & clean$State == "California")
length(orlando)
mean(clean$Walk[orlando])
mean(clean$Walk[chicago])
orlando = which(clean$County == "Los Angeles")
length(orlando)
chicago = which(clean$County == "Cook" & clean$State == "Illinois")
LA = which(clean$County == "Los Angeles")
mean(clean$Walk[chicago]); mean(clean$Walk[LA])
obs = mean(clean$Walk[LA]) - mean(clean$Walk[chicago]); obs
#We can't just permute the County column, because Cook county exists in multiple states
#So we create a new city column
is.chicago = as.numeric(clean$County == "Cook" & clean$State == "Illinois"); head(is.chicago)
length(is.chicago); sum(is.chicago)  #Seems right
chicago = which(clean$County == "Cook" & clean$State == "Illinois"); length(chicago)
LA = which(clean$County == "Los Angeles"); length(LA)
is.LA = as.numeric(clean$County == "Los Angeles"); head(is.LA)
length(is.LA); sum(is.LA)  #Seems right
city = is.chicago + 2*is.LA; head(city) #Since no tract is both in Chicago and Los Angeles, there is no overlap. Chicago tracts will be a 1, Los Angeles tracts are a 2, and everything else is 0
sum(city == 1); sum(city == 2)  #Perfect
#Now replace Chicago with a random sample of all the data
permute <- sample(city); head(permute)   #permuted city column
ChicagoAvg <- sum(clean$Walk*(permute == 1))/sum(permute == 1); ChicagoAvg
LosAvg <- sum(clean$Walk*(permute == 2))/sum(permute == 2); LosAvg
LosAvg - ChicagoAvg    #as likely to be negative or positive
#Repeat 10000 times
N <- 10000
diffs <- numeric(N)
for (i in 1:N){
permute <- sample(city); head(permute)
ChicagoAvg <- sum(clean$Walk*(permute == 1))/sum(permute == 1)
LosAvg <- sum(clean$Walk*(permute == 2))/sum(permute == 2)
diffs[i] <- LosAvg - ChicagoAvg
} #takes about a minute
mean(diffs)
hist(diffs, breaks = "FD", xlim = c(-3,3))
hist(diffs, breaks = "FD")
hist(diffs, breaks = "FD", xlim = c(-1.5,1.5))
#Now display the observed difference on the histogram
abline(v = obs, col = "red")
#What is the probability (the P value) that a difference this large could have arisen with a random subset?
pvalue <- (sum(diffs >= obs)+1)/(N+1); pvalue #greater than 0.05
#The proportion of people who walk to work in Los Angeles is not statistically greater than the proportion of people who walk to work in Chicago.
1-p
#What is the probability (the P value) that a difference this large could have arisen with a random subset?
p <- (sum(diffs >= obs)+1)/(N+1); p #greater than 0.05
#The proportion of people who walk to work in Los Angeles is not statistically greater than the proportion of people who walk to work in Chicago.
1-p
is.LA = as.numeric(clean$County == "Los Angeles", clean$State == "California"); head(is.LA)
length(is.LA); sum(is.LA)  #Seems right
hist(diffs, breaks = "FD")
hist(diffs, breaks = "FD", xlim = c(-1.5,1.5))
#Now display the observed difference on the histogram
abline(v = obs, col = "red")
################## Massimo ##################
(349-191)/349
################## Massimo ##################
(349-191)
# Asian
ggplot(df, aes(percentA, income)) +
geom_point(color = "red", size = 0.5) +
geom_smooth(method = "lm", color ="blue") +
xlab("Percent of Asian People in Tract") +
ylab("Average Income of Tract")
if (!require(ggplot2)) install.packages("ggplot2"); library(ggplot2)
#Histogram with Normal Distribution added
hist(clean$Income)
h = hist(clean$Income)
h$density = h$counts/sum(h$counts)
plot(h,freq=FALSE)
hist(clean$Income, breaks = "FD", probability = TRUE)
#To find the best fitting normal distribution, compute the mean and variance of the data
mu <- mean(clean$Income); mu
var <- var(clean$Income)
sigma <- sd(clean$Income)     #estimates square root of the population variance
curve(dnorm(x, mu, sigma), from = 0, to = 250000, add = TRUE, col = "red")
#Visualizng the percentage of a race in a population w.r.t. the average income of the population
percentA <- clean$Asian / 100       # Asian
percentB <- clean$Black / 100       # Black
percentH <- clean$Hispanic / 100    # Hispanic
percentN <- clean$Native / 100      # Native
percentP <- clean$Pacific / 100     # Pacific
percentW <- clean$White / 100       # White
income <-  clean$Income
# ggplotting the data: fulfilling "Nicely labeled graphics using ggplot, with good use of color, line styles, etc., that tell a convincing story"
df <- data.frame(
percentA,      # Asian
percentB,      # Black
percentH,   # Hispanic
percentN,    # Native
percentP,  # Pacific
percentW,       # White
income
)
# Asian
ggplot(df, aes(percentA, income)) +
geom_point(color = "red", size = 0.5) +
geom_smooth(method = "lm", color ="blue") +
xlab("Percent of Asian People in Tract") +
ylab("Average Income of Tract")
library(ggplot2)
if (!require(ggplot2)) install.packages("ggplot2"); library(ggplot2)
if (!require(randomForest)) install.packages("randomForest"); library(randomForest)
if (!require(foreign)) install.packages("foreign"); library(foreign)
if (!require(haven)) install.packages("haven"); library(haven)
if (!require(rpart)) install.packages("rpart"); library(rpart)
# Asian
ggplot(df, aes(percentA, income)) +
geom_point(color = "red", size = 0.5) +
geom_smooth(method = "lm", color ="blue") +
xlab("Percent of Asian People in Tract") +
ylab("Average Income of Tract")
# Linear regression on the above scatter plots
Percent <- c(0,1)
Income <- c(0, 200000)
plot(Percent, Income, pch=".") # To clear plot space but keep axes in tact
abline(lm(income ~ percentH), col = "red") # Hispanic
abline(lm(income ~ percentW), col = "orange") # White
abline(lm(income ~ percentB), col = "yellow") # Black
abline(lm(income ~ percentN), col = "green") # Native
abline(lm(income ~ percentA), col = "blue") # Asian
abline(lm(income ~ percentP), col = "violet") # Pacific
#Storing predictor variables
#Order data in stata so all predictors appear in right-most columns
vars <- colnames(clean[18:ncol(clean)])
vars
#OLS Regression
to_hat <- with(clean[clean$Income>0,], lm(reformulate(vars, "Income")))
summary(to_hat)
rank_hat_ols = predict(to_hat, newdata=clean)
summary(rank_hat_ols); hist(rank_hat_ols, xlab="Predicted Rates - OLS")
# rank_hat_tree <- predict(one_tree, newdata=clean)
# table(rank_hat_tree)
# hist(rank_hat_tree, xlab="Predicted Rates - Single Tree")
#
# plot(one_tree) # plot tree
# text(one_tree) # add labels to tree
# # print complexity parameter table using cross validation
# printcp(one_tree)
#
# #Random Forest from 500 Bootstrapped Samples
forest_hat <- randomForest(reformulate(vars, "Income"), ntree=100, mtry=20, maxnodes=50
,importance=TRUE, do.trace=25, data=clean[clean$Income>0,])
getTree(forest_hat, 100, labelVar = TRUE) #Text Representation of Tree
rank_hat_forest <- predict(forest_hat, newdata=clean,type="response")
summary(rank_hat_forest); hist(rank_hat_forest, xlab="Predicted Rates - Random Forest")
